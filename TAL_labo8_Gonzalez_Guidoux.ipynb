{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 8 : modèles de langage / Cloze Test\n",
    "Par Guidoux Vincent et Gonzalez Montes Nathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif et plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce labo est d'entraîner des modèles de langues (EN : language models) sous NLTK en utilisant le package nltk.lm. Les modèles seront entraînés sur des romans de Balzac en français\n",
    "(fournis par le projet Gutenberg), et leurs performances seront mesurées par leur perplexité sur de nouveaux textes. Les modèles serviront également à deviner des mots cachés dans un texte, et ici leurs performances seront comparées à celles des humains sur cette même tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vincent\n",
      "[nltk_data]     Guidoux\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.lm\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "import os, codecs\n",
    "from urllib import request\n",
    "import random\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenir les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger les dix romans de la Comédie humaine de Balzac en français, enlever les notices en anglais au début et à la fin, puis les assembler en un corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_gutenberg_raw(url):\n",
    "    print(\"dowloading \\\"{}\\\" ... \".format(url))\n",
    "    \n",
    "    response = request.urlopen(url)\n",
    "    raw = response.read().decode('utf8')\n",
    "    \n",
    "    # enlever les notices en anglais au début \n",
    "    begin = raw.find(\"Libraries)\") + 10\n",
    "    # et à la fin\n",
    "    end = raw.find(\"*** END OF THIS PROJECT\")\n",
    "    \n",
    "    return raw[begin:end].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_1 = \"https://www.gutenberg.org/ebooks/41211.txt.utf-8\"\n",
    "volume_2 = \"https://www.gutenberg.org/files/43851/43851-0.txt\"\n",
    "volume_3 = \"https://www.gutenberg.org/files/45060/45060-0.txt\"\n",
    "volume_4 = \"https://www.gutenberg.org/files/48082/48082-0.txt\"\n",
    "volume_5 = \"https://www.gutenberg.org/files/49482/49482-0.txt\"\n",
    "volume_6 = \"https://www.gutenberg.org/files/51381/51381-0.txt\"\n",
    "volume_7 = \"https://www.gutenberg.org/files/52831/52831-0.txt\"\n",
    "volume_8 = \"https://www.gutenberg.org/files/54723/54723-0.txt\"\n",
    "volume_9 = \"https://www.gutenberg.org/files/55860/55860-0.txt\"\n",
    "volume_10 = \"https://www.gutenberg.org/files/58244/58244-0.txt\"\n",
    "\n",
    "balzac = [volume_1, \n",
    "          volume_2, \n",
    "          volume_3, \n",
    "          volume_4, \n",
    "          volume_5, \n",
    "          volume_6, \n",
    "          volume_7, \n",
    "          volume_8,\n",
    "          volume_9, \n",
    "          volume_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser une procédure à laquelle on donnera la liste de noms de fichiers ou des URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dowloading \"https://www.gutenberg.org/ebooks/41211.txt.utf-8\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/43851/43851-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/45060/45060-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/48082/48082-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/49482/49482-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/51381/51381-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/52831/52831-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/54723/54723-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/55860/55860-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/58244/58244-0.txt\" ... \n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\n",
    "\n",
    "for volume_url in balzac:\n",
    "    corpus += dl_gutenberg_raw(volume_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 12214531 caractères dans ce corpus.\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} caractères dans ce corpus.\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder le texte résultant : quelle taille fait-il en Ko ou Mo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"la_comedie_humaine.txt\"\n",
    "\n",
    "if os.path.exists(filename1): \n",
    "    os.remove(filename1)\n",
    "fd = codecs.open(filename1, 'a', 'utf8')\n",
    "\n",
    "try:\n",
    "    fd.write(corpus)\n",
    "    \n",
    "\n",
    "finally:  \n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il fait **12'258 [ko]** et **12 [Mo]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenter et tokenizer en une liste de listes de mots, y compris les ponctuations (une liste = une phrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_nettoye = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_nettoye = corpus_nettoye.replace('.\\r\\n',' ') # on nettoie les retours à la ligne\n",
    "# corpus_nettoye = corpus_nettoye.replace('\\r\\n.',' ') # on nettoie les retours à la ligne\n",
    "# corpus_nettoye = corpus_nettoye.replace('\\r\\n',' ') # on nettoie les retours à la ligne\n",
    "corpus_nettoye = corpus_nettoye.replace('_',' ') # on nettoie les _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = nltk.sent_tokenize(corpus_nettoye, language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 101622 phrases dans le corpus\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} phrases dans le corpus\".format(len(tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [nltk.word_tokenize(sentence) for sentence in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_nb = 0\n",
    "for sentence in tokenized:\n",
    "    word_nb += len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2335507 mots dans ce corpus\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} mots dans ce corpus\".format(word_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized[87:93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized[1506:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized[7000:7005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire un fragment (environ 2000 mots) qui servira de donnée de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_test(sentences):\n",
    "    \n",
    "    train_percentage = 0.03\n",
    "\n",
    "    random.shuffle(sentences)\n",
    "    \n",
    "    sentences_length = len(sentences)\n",
    "    \n",
    "    train_set_length = int(len(sentences) * train_percentage)\n",
    "    \n",
    "    test_set = sentences[ :train_set_length]\n",
    "    \n",
    "    train_set = sentences[train_set_length: ]\n",
    "\n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = separate_train_test(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 98574 phrases dans le train_set et 3048 dans le test_set\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} phrases dans le train_set et {} dans le test_set\".format(\n",
    "        len(train_set),\n",
    "        len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un premier modèle de langage de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant les instructions disponibles pour le module NLTK LM, entraîner un modèle de langage sur les données d'entraînement. Attention, le package lm n'est disponible qu'à partir de NLTK version 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencer avec un modèle MLE à l'ordre 2, comme montré dans le tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vocab = padded_everygram_pipeline(order, tokenized)\n",
    "#train, vocab = padded_everygram_pipeline(order, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = MLE(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cela a pris 92.966 secondes pour entraîner le modèle d'ordre 5\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "lm.fit(train, vocab)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Cela a pris {:.3f} secondes pour entraîner le modèle d'ordre {}\".format(\n",
    "            (end-begin), order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la perplexité du modèle sur l’ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générer quelques phrases dans le style de Balzac selon les explications de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_sentence(length, sentence_nb):\n",
    "\n",
    "    for i in range(sentence_nb):\n",
    "        sentence = \"{}. \".format(i)\n",
    "        for word in lm.generate(length):\n",
    "            if word != \"<s>\" and word != \"</s>\":\n",
    "                sentence += word + \" \"\n",
    "        print(sentence + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. semblables à celles du serpent , peuvent à \n",
      "\n",
      "1. utilité . \n",
      "\n",
      "2. politique . \n",
      "\n",
      "3. pronostics de ma mère . \n",
      "\n",
      "4. \n",
      "\n",
      "5. suffit à faire comprendre l'importance des petits détails \n",
      "\n",
      "6. mots spirituels qu'elle disait à tout propos et \n",
      "\n",
      "7. la première fois depuis long-temps , le bonheur \n",
      "\n",
      "8. \n",
      "\n",
      "9. \n",
      "\n",
      "10. il accumule tant de petites pièces et de \n",
      "\n",
      "11. je n'ai pas attendu , dans \n",
      "\n",
      "12. -- oh ! \n",
      "\n",
      "13. pierrotin cria un certain hi ! \n",
      "\n",
      "14. ferait un intendant . \n",
      "\n",
      "15. ceux qui vous ont haïe ou blessée . \n",
      "\n",
      "16. de maternel . \n",
      "\n",
      "17. \n",
      "\n",
      "18. , mène à la maison par une laiterie \n",
      "\n",
      "19. : —hé ! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_generated_sentence(8, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. dans ce temps-là , faisaient de la monarchie et de la religion , attendrie par tant de repentir , bettina ne s'endormit pas sans \n",
      "\n",
      "1. possible de ces magnifiques intuitions . \n",
      "\n",
      "2. , dans l'intérêt public bien entendu . \n",
      "\n",
      "3. en toi ; en toi que je regardais comme le plus pur des vendéens . \n",
      "\n",
      "4. « sa » ( la noblesse dans toute sa beauté ) . \n",
      "\n",
      "5. le redoutait , semblable au malheureux condamné à mort qui voudrait en avoir fini avec la vie , enfant , et j'ai peur que ce \n",
      "\n",
      "6. leur proie . \n",
      "\n",
      "7. de clagny , voulut le faire enrager par une de ces œuvres dont parlent les jeunes gens , montés sur des si , franchissent toutes \n",
      "\n",
      "8. \n",
      "\n",
      "9. qui , pour la distinguer des galeries-de-bois . \n",
      "\n",
      "10. \n",
      "\n",
      "11. ? \n",
      "\n",
      "12. et se défont . \n",
      "\n",
      "13. madame de vandenesse fît une petite moue quand il voulait se dispenser d'être à un bal , à un concert , à une promenade , \n",
      "\n",
      "14. a pas exemple de deux hommes parvenus par une même voie . \n",
      "\n",
      "15. est grand . \n",
      "\n",
      "16. ce sera le dieu des jardins ! \n",
      "\n",
      "17. patins en fer , vêtue d'indienne et mal tenue , ne pouvait être qu'un noir scélérat . \n",
      "\n",
      "18. partie . \n",
      "\n",
      "19. ! \n",
      "\n",
      "20. et , notez ce point ! \n",
      "\n",
      "21. signé ? \n",
      "\n",
      "22. \n",
      "\n",
      "23. admirateurs , de balzac . \n",
      "\n",
      "24. auquel elles sont soumises n ' a pu , dit ursule , mais un homme d'une puissance extraordinaire , un homme aussi grand qu'on peut \n",
      "\n",
      "25. ses filles , hein ? \n",
      "\n",
      "26. rendaient à la sainte beauté . \n",
      "\n",
      "27. néanmoins madame de rochefide , au milieu du dos , et produisit entre le gilet et le pantalon une solution de \n",
      "\n",
      "28. chaque fois qu'il sortait de chez madame d'aiglemont , la mise était en harmonie avec les sentiments . \n",
      "\n",
      "29. \n",
      "\n",
      "30. composition , si vous m'offrez le temps et l'espace , à force de parler éternité , de perpétuer l'amour du général en ce monde et \n",
      "\n",
      "31. \n",
      "\n",
      "32. tracassiers , sans âme et d'une économie sordide , le frère et la sœur se consultaient sur leurs intentions . \n",
      "\n",
      "33. , sa compassion s'exerçait sur un autre que sur elle-même et sur ses privations . \n",
      "\n",
      "34. dauriat tint lieu de conscience et d'inspiration . \n",
      "\n",
      "35. , dans la manière dont il le soldait , tout en disant de mois en mois , au fond du cœur ? \n",
      "\n",
      "36. , lui , qu'il devait mademoiselle grandet à un dépit amoureux ; aussi s'empressa-t-il d'exécuter ses ordres avec la plus grande attention . \n",
      "\n",
      "37. , une provision de chocolat , et tous les moyens de séduction , et enleva caroline . \n",
      "\n",
      "38. madame la comtesse sans vous en prévenir ; mais il m ' a paru vide , et il a bien trouvé son lot ; il \n",
      "\n",
      "39. un galant homme , un homme de saint-flour . \n",
      "\n",
      "40. , n'est-ce pas des peccadilles commises à tous les étages ; le piéton industriel , armé d'une sacoche ou muni d'un paquet , traduisant la \n",
      "\n",
      "41. fut entraîné par lousteau qui ne lui laissa pas le temps de se reconnaître . \n",
      "\n",
      "42. pas trouvés assez aimables , dit l'abbé troubert aux amis de mademoiselle gamard lorsqu'elle fut obligée de renoncer à ses soirées . \n",
      "\n",
      "43. le froid regard des gens d'affaires , devina les sentiments qui l'agitaient et lui dit : —ma mère , voilà un monsieur qui veut vous \n",
      "\n",
      "44. ceux qui sont arrivés , quibuscumque viis , à la politique , elles jugèrent , avec ce tact particulier aux femmes , eut bientôt deviné \n",
      "\n",
      "45. appuyé par les banquiers royalistes du tillet et nucingen , le président tiphaine eut occasion de rendre service au ministère , il fut un de \n",
      "\n",
      "46. mois se passèrent . \n",
      "\n",
      "47. il se coucha et s'endormit accablé de fatigue . \n",
      "\n",
      "48. voilà ma vie , toute ma vie , je ne m'immiscerais , certes , en aucune manière dans les affaires d'un homme \n",
      "\n",
      "49. autrement que par oui et non aux demandes , naturelles en semblable occurrence , les gobseck , les palma , les werbrust et gigonnet , \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_generated_sentence(25, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un second modèle de langage de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant par exemple le modèle de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tester aussi sur le corpus de test et comparer les scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloze test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer un mot sur 7 dans le corpus de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode lm.generate avec du contexte, demander au modèle de langage de prédire ces mots (en utilisant donc 2-4 mots précédents). Quelle est la performance du système ? Comparer les modèles générés en (2) et en (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générez un texte avec les mots en question (1 mot sur 7) remplacés par des blancs, et passez-le à un autre binôme : quelle est leur performance pour deviner les mots ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merci d’envoyer votre notebook Jupyter par email au professeur avant le vendredi 14 juin à 23h59."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
