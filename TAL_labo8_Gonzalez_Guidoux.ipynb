{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 8 : modèles de langage / Cloze Test\n",
    "Par Guidoux Vincent et Gonzalez Montes Nathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif et plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce labo est d'entraîner des modèles de langues (EN : language models) sous NLTK en utilisant le package nltk.lm. Les modèles seront entraînés sur des romans de Balzac en français\n",
    "(fournis par le projet Gutenberg), et leurs performances seront mesurées par leur perplexité sur de nouveaux textes. Les modèles serviront également à deviner des mots cachés dans un texte, et ici leurs performances seront comparées à celles des humains sur cette même tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vincent\n",
      "[nltk_data]     Guidoux\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.lm\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "import os, codecs\n",
    "from urllib import request\n",
    "import random\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenir les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger les dix romans de la Comédie humaine de Balzac en français, enlever les notices en anglais au début et à la fin, puis les assembler en un corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_gutenberg_raw(url):\n",
    "    print(\"dowloading \\\"{}\\\" ... \".format(url))\n",
    "    \n",
    "    response = request.urlopen(url)\n",
    "    raw = response.read().decode('utf8')\n",
    "    \n",
    "    # enlever les notices en anglais au début \n",
    "    begin = raw.find(\"Libraries)\") + 10\n",
    "    # et à la fin\n",
    "    end = raw.find(\"*** END OF THIS PROJECT\")\n",
    "    \n",
    "    return raw[begin:end].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_1 = \"https://www.gutenberg.org/ebooks/41211.txt.utf-8\"\n",
    "volume_2 = \"https://www.gutenberg.org/files/43851/43851-0.txt\"\n",
    "volume_3 = \"https://www.gutenberg.org/files/45060/45060-0.txt\"\n",
    "volume_4 = \"https://www.gutenberg.org/files/48082/48082-0.txt\"\n",
    "volume_5 = \"https://www.gutenberg.org/files/49482/49482-0.txt\"\n",
    "volume_6 = \"https://www.gutenberg.org/files/51381/51381-0.txt\"\n",
    "volume_7 = \"https://www.gutenberg.org/files/52831/52831-0.txt\"\n",
    "volume_8 = \"https://www.gutenberg.org/files/54723/54723-0.txt\"\n",
    "volume_9 = \"https://www.gutenberg.org/files/55860/55860-0.txt\"\n",
    "volume_10 = \"https://www.gutenberg.org/files/58244/58244-0.txt\"\n",
    "\n",
    "balzac = [volume_1, \n",
    "          volume_2, \n",
    "          volume_3, \n",
    "          volume_4, \n",
    "          volume_5, \n",
    "          volume_6, \n",
    "          volume_7, \n",
    "          volume_8,\n",
    "          volume_9, \n",
    "          volume_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser une procédure à laquelle on donnera la liste de noms de fichiers ou des URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dowloading \"https://www.gutenberg.org/ebooks/41211.txt.utf-8\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/43851/43851-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/45060/45060-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/48082/48082-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/49482/49482-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/51381/51381-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/52831/52831-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/54723/54723-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/55860/55860-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/58244/58244-0.txt\" ... \n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\n",
    "\n",
    "for volume_url in balzac:\n",
    "    corpus += dl_gutenberg_raw(volume_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 12214531 caractères dans ce corpus.\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} caractères dans ce corpus.\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder le texte résultant : quelle taille fait-il en Ko ou Mo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"la_comedie_humaine.txt\"\n",
    "\n",
    "if os.path.exists(filename1): \n",
    "    os.remove(filename1)\n",
    "fd = codecs.open(filename1, 'a', 'utf8')\n",
    "\n",
    "try:\n",
    "    fd.write(corpus)\n",
    "    \n",
    "\n",
    "finally:  \n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il fait **12'258 [ko]** et **12 [Mo]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenter et tokenizer en une liste de listes de mots, y compris les ponctuations (une liste = une phrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_nettoye = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_nettoye = corpus_nettoye.replace('.\\r\\n',' ') # on nettoie les retours à la ligne\n",
    "# corpus_nettoye = corpus_nettoye.replace('\\r\\n.',' ') # on nettoie les retours à la ligne\n",
    "# corpus_nettoye = corpus_nettoye.replace('\\r\\n',' ') # on nettoie les retours à la ligne\n",
    "corpus_nettoye = corpus_nettoye.replace('_',' ') # on nettoie les _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = nltk.sent_tokenize(corpus_nettoye, language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 101622 phrases dans le corpus\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} phrases dans le corpus\".format(len(tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [nltk.word_tokenize(sentence) for sentence in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_nb = 0\n",
    "for sentence in tokenized:\n",
    "    word_nb += len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2335507 mots dans ce corpus\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} mots dans ce corpus\".format(word_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['balzac',\n",
       "  ',',\n",
       "  'de',\n",
       "  'peur',\n",
       "  \"qu'ils\",\n",
       "  'ne',\n",
       "  \"s'ébruitassent\",\n",
       "  ',',\n",
       "  'les',\n",
       "  'changeait',\n",
       "  'souvent',\n",
       "  '.'],\n",
       " ['nous',\n",
       "  'nous',\n",
       "  'souvenons',\n",
       "  'de',\n",
       "  'ceux-ci',\n",
       "  ':',\n",
       "  'au',\n",
       "  'portier',\n",
       "  \"l'on\",\n",
       "  'disait',\n",
       "  ':',\n",
       "  '«',\n",
       "  'la',\n",
       "  'saison',\n",
       "  'des',\n",
       "  'prunes',\n",
       "  'est',\n",
       "  'arrivée',\n",
       "  ',',\n",
       "  '»',\n",
       "  'et',\n",
       "  'il',\n",
       "  'vous',\n",
       "  'laissait',\n",
       "  'franchir',\n",
       "  'le',\n",
       "  'seuil',\n",
       "  ';',\n",
       "  'au',\n",
       "  'domestique',\n",
       "  'accouru',\n",
       "  'sur',\n",
       "  \"l'escalier\",\n",
       "  'au',\n",
       "  'son',\n",
       "  'de',\n",
       "  'la',\n",
       "  'cloche',\n",
       "  ',',\n",
       "  'il',\n",
       "  'fallait',\n",
       "  'murmurer',\n",
       "  ':',\n",
       "  '«',\n",
       "  \"j'apporte\",\n",
       "  'des',\n",
       "  'dentelles',\n",
       "  'de',\n",
       "  'belgique',\n",
       "  ',',\n",
       "  '»',\n",
       "  'et',\n",
       "  'si',\n",
       "  'vous',\n",
       "  'assuriez',\n",
       "  'au',\n",
       "  'valet',\n",
       "  'de',\n",
       "  'chambre',\n",
       "  'que',\n",
       "  '«',\n",
       "  'madame',\n",
       "  'bertrand',\n",
       "  'était',\n",
       "  'en',\n",
       "  'bonne',\n",
       "  'santé',\n",
       "  ',',\n",
       "  '»',\n",
       "  'on',\n",
       "  'vous',\n",
       "  'introduisait',\n",
       "  'enfin',\n",
       "  '.'],\n",
       " ['ces',\n",
       "  'enfantillages',\n",
       "  'amusaient',\n",
       "  'beaucoup',\n",
       "  'balzac',\n",
       "  ';',\n",
       "  'ils',\n",
       "  'étaient',\n",
       "  'peut-être',\n",
       "  'nécessaires',\n",
       "  'pour',\n",
       "  'écarter',\n",
       "  'les',\n",
       "  'fâcheux',\n",
       "  'et',\n",
       "  \"d'autres\",\n",
       "  'visiteurs',\n",
       "  'plus',\n",
       "  'désagréables',\n",
       "  'encore',\n",
       "  '.'],\n",
       " ['un',\n",
       "  'des',\n",
       "  'rêves',\n",
       "  'de',\n",
       "  'balzac',\n",
       "  'était',\n",
       "  \"l'amitié\",\n",
       "  'héroïque',\n",
       "  'et',\n",
       "  'dévouée',\n",
       "  ',',\n",
       "  'deux',\n",
       "  'âmes',\n",
       "  ',',\n",
       "  'deux',\n",
       "  'courages',\n",
       "  ',',\n",
       "  'deux',\n",
       "  'intelligences',\n",
       "  'fondues',\n",
       "  'dans',\n",
       "  'la',\n",
       "  'même',\n",
       "  'volonté',\n",
       "  '.'],\n",
       " ['il',\n",
       "  'voulut',\n",
       "  'former',\n",
       "  'une',\n",
       "  'association',\n",
       "  'dans',\n",
       "  'le',\n",
       "  'goût',\n",
       "  'de',\n",
       "  'celle',\n",
       "  'qui',\n",
       "  'réunissait',\n",
       "  'ferragus',\n",
       "  ',',\n",
       "  'montriveau',\n",
       "  ',',\n",
       "  'ronquerolles',\n",
       "  'et',\n",
       "  'leurs',\n",
       "  'compagnons',\n",
       "  '.'],\n",
       " ['seulement',\n",
       "  'il',\n",
       "  'ne',\n",
       "  \"s'agissait\",\n",
       "  'pas',\n",
       "  'de',\n",
       "  'coups',\n",
       "  'si',\n",
       "  'hardis',\n",
       "  ';',\n",
       "  'un',\n",
       "  'certain',\n",
       "  'nombre',\n",
       "  \"d'amis\",\n",
       "  'devaient',\n",
       "  'se',\n",
       "  'prêter',\n",
       "  'aide',\n",
       "  'et',\n",
       "  'secours',\n",
       "  'en',\n",
       "  'toute',\n",
       "  'occasion',\n",
       "  'et',\n",
       "  'travailler',\n",
       "  ',',\n",
       "  'selon',\n",
       "  'leurs',\n",
       "  'forces',\n",
       "  ',',\n",
       "  'au',\n",
       "  'succès',\n",
       "  'ou',\n",
       "  'à',\n",
       "  'la',\n",
       "  'fortune',\n",
       "  'de',\n",
       "  'celui',\n",
       "  'qui',\n",
       "  'serait',\n",
       "  'désigné',\n",
       "  ',',\n",
       "  'à',\n",
       "  'charge',\n",
       "  'de',\n",
       "  'revanche',\n",
       "  ',',\n",
       "  'bien',\n",
       "  'entendu',\n",
       "  '.']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[87:93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lorsque',\n",
       "  'le',\n",
       "  'chef',\n",
       "  'de',\n",
       "  'la',\n",
       "  'famille',\n",
       "  'éprouva',\n",
       "  'quelque',\n",
       "  'refroidissement',\n",
       "  'dans',\n",
       "  'la',\n",
       "  'tacite',\n",
       "  'et',\n",
       "  'précaire',\n",
       "  'amitié',\n",
       "  'du',\n",
       "  'monarque',\n",
       "  ',',\n",
       "  'il',\n",
       "  'trembla',\n",
       "  \"d'autant\",\n",
       "  'plus',\n",
       "  ',',\n",
       "  'que',\n",
       "  ',',\n",
       "  'par',\n",
       "  'suite',\n",
       "  'des',\n",
       "  'défis',\n",
       "  'railleurs',\n",
       "  'de',\n",
       "  'ses',\n",
       "  'soeurs',\n",
       "  ',',\n",
       "  'jamais',\n",
       "  'sa',\n",
       "  'fille',\n",
       "  'chérie',\n",
       "  \"n'avait\",\n",
       "  'jeté',\n",
       "  'ses',\n",
       "  'vues',\n",
       "  'si',\n",
       "  'haut',\n",
       "  '.'],\n",
       " ['au',\n",
       "  'milieu',\n",
       "  'de',\n",
       "  'ces',\n",
       "  'circonstances',\n",
       "  'et',\n",
       "  'au',\n",
       "  'moment',\n",
       "  'où',\n",
       "  'cette',\n",
       "  'petite',\n",
       "  'lutte',\n",
       "  'domestique',\n",
       "  'était',\n",
       "  'devenue',\n",
       "  'fort',\n",
       "  'grave',\n",
       "  ',',\n",
       "  'le',\n",
       "  'monarque',\n",
       "  ',',\n",
       "  'auprès',\n",
       "  'duquel',\n",
       "  'monsieur',\n",
       "  'de',\n",
       "  'fontaine',\n",
       "  'croyait',\n",
       "  'rentrer',\n",
       "  'en',\n",
       "  'grâce',\n",
       "  ',',\n",
       "  'fut',\n",
       "  'attaqué',\n",
       "  'de',\n",
       "  'la',\n",
       "  'maladie',\n",
       "  'dont',\n",
       "  'il',\n",
       "  'devait',\n",
       "  'périr',\n",
       "  '.'],\n",
       " ['le',\n",
       "  'grand',\n",
       "  'politique',\n",
       "  'qui',\n",
       "  'sut',\n",
       "  'si',\n",
       "  'bien',\n",
       "  'conduire',\n",
       "  'sa',\n",
       "  'nauf',\n",
       "  'au',\n",
       "  'sein',\n",
       "  'des',\n",
       "  'orages',\n",
       "  'ne',\n",
       "  'tarda',\n",
       "  'pas',\n",
       "  'à',\n",
       "  'succomber',\n",
       "  '.'],\n",
       " ['certain',\n",
       "  'de',\n",
       "  'la',\n",
       "  'faveur',\n",
       "  'à',\n",
       "  'venir',\n",
       "  ',',\n",
       "  'le',\n",
       "  'comte',\n",
       "  'de',\n",
       "  'fontaine',\n",
       "  'fit',\n",
       "  'donc',\n",
       "  'les',\n",
       "  'plus',\n",
       "  'grands',\n",
       "  'efforts',\n",
       "  'pour',\n",
       "  'rassembler',\n",
       "  'autour',\n",
       "  'de',\n",
       "  'sa',\n",
       "  'dernière',\n",
       "  'fille',\n",
       "  \"l'élite\",\n",
       "  'des',\n",
       "  'jeunes',\n",
       "  'gens',\n",
       "  'à',\n",
       "  'marier',\n",
       "  '.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[1506:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['après',\n",
       "  'le',\n",
       "  'dîner',\n",
       "  ',',\n",
       "  'adam',\n",
       "  'les',\n",
       "  'laissa',\n",
       "  'seuls',\n",
       "  ',',\n",
       "  'et',\n",
       "  'clémentine',\n",
       "  'gronda',\n",
       "  'thaddée',\n",
       "  'de',\n",
       "  'manière',\n",
       "  'à',\n",
       "  'lui',\n",
       "  'faire',\n",
       "  'sentir',\n",
       "  \"qu'elle\",\n",
       "  'ne',\n",
       "  'le',\n",
       "  'voulait',\n",
       "  'plus',\n",
       "  'au',\n",
       "  'logis',\n",
       "  '.'],\n",
       " ['--',\n",
       "  'oui',\n",
       "  ',',\n",
       "  'madame',\n",
       "  ',',\n",
       "  'dit',\n",
       "  'humblement',\n",
       "  'thaddée',\n",
       "  ',',\n",
       "  'vous',\n",
       "  'avez',\n",
       "  'raison',\n",
       "  ',',\n",
       "  'je',\n",
       "  'suis',\n",
       "  'un',\n",
       "  'misérable',\n",
       "  ',',\n",
       "  \"j'avais\",\n",
       "  'donné',\n",
       "  'ma',\n",
       "  'parole',\n",
       "  '.'],\n",
       " ['mais', 'que', 'voulez-vous', '?'],\n",
       " [\"j'avais\",\n",
       "  'remis',\n",
       "  'à',\n",
       "  'quitter',\n",
       "  'malaga',\n",
       "  'après',\n",
       "  'le',\n",
       "  'carnaval',\n",
       "  '...',\n",
       "  'je',\n",
       "  'serai',\n",
       "  'franc',\n",
       "  ',',\n",
       "  \"d'ailleurs\",\n",
       "  ':',\n",
       "  'cette',\n",
       "  'femme',\n",
       "  'exerce',\n",
       "  'un',\n",
       "  'tel',\n",
       "  'empire',\n",
       "  'sur',\n",
       "  'moi',\n",
       "  'que',\n",
       "  '...',\n",
       "  '--',\n",
       "  'une',\n",
       "  'femme',\n",
       "  'qui',\n",
       "  'se',\n",
       "  'fait',\n",
       "  'mettre',\n",
       "  'à',\n",
       "  'la',\n",
       "  'porte',\n",
       "  'de',\n",
       "  'chez',\n",
       "  'musard',\n",
       "  'par',\n",
       "  'les',\n",
       "  'sergents',\n",
       "  'de',\n",
       "  'ville',\n",
       "  ',',\n",
       "  'et',\n",
       "  'pour',\n",
       "  'quelle',\n",
       "  'danse',\n",
       "  '!'],\n",
       " ['--',\n",
       "  \"j'en\",\n",
       "  'conviens',\n",
       "  ',',\n",
       "  'je',\n",
       "  'passe',\n",
       "  'condamnation',\n",
       "  ',',\n",
       "  'je',\n",
       "  'quitterai',\n",
       "  'votre',\n",
       "  'maison',\n",
       "  ';',\n",
       "  'mais',\n",
       "  'vous',\n",
       "  'connaissez',\n",
       "  'adam',\n",
       "  '.']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized[7000:7005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire un fragment (environ 2000 mots) qui servira de donnée de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_test(sentences):\n",
    "    \n",
    "    train_percentage = 0.03\n",
    "\n",
    "    random.shuffle(sentences)\n",
    "    \n",
    "    sentences_length = len(sentences)\n",
    "    \n",
    "    train_set_length = int(len(sentences) * train_percentage)\n",
    "    \n",
    "    test_set = sentences[ :train_set_length]\n",
    "    \n",
    "    train_set = sentences[train_set_length: ]\n",
    "\n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = separate_train_test(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 98574 phrases dans le train_set et 3048 dans le test_set\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} phrases dans le train_set et {} dans le test_set\".format(\n",
    "        len(train_set),\n",
    "        len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un premier modèle de langage de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant les instructions disponibles pour le module NLTK LM, entraîner un modèle de langage sur les données d'entraînement. Attention, le package lm n'est disponible qu'à partir de NLTK version 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencer avec un modèle MLE à l'ordre 2, comme montré dans le tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, vocab = padded_everygram_pipeline(order, tokenized)\n",
    "#train, vocab = padded_everygram_pipeline(order, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = MLE(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cela a pris 98.203 secondes pour entraîner le modèle d'ordre 5\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "lm.fit(train, vocab)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Cela a pris {:.3f} secondes pour entraîner le modèle d'ordre {}\".format(\n",
    "            (end-begin), order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la perplexité du modèle sur l’ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générer quelques phrases dans le style de Balzac selon les explications de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_sentence(length, sentence_nb):\n",
    "\n",
    "    for i in range(sentence_nb):\n",
    "        sentence = \"{}. \".format(i)\n",
    "        for word in lm.generate(length):\n",
    "            if word != \"<s>\" and word != \"</s>\":\n",
    "                sentence += word + \" \"\n",
    "        print(sentence + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. la première et se mit auprès d'elle pour la séparer du jeune vicomte . \n",
      "\n",
      "1. un bourbier . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_generated_sentence(16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. jour de sa réhabilitation . \n",
      "\n",
      "1. vie . \n",
      "\n",
      "2. , fluet , et ne l'avance pas ; ses yeux , où les scintillements des pierres semblaient se répéter , brillaient d'un feu surnaturel ; \n",
      "\n",
      "3. \n",
      "\n",
      "4. dans l'omnipotence de leurs modes , dans la diversité de leurs mélancolies , avec les teintes de leurs méditatives extases , avec les jets impétueux \n",
      "\n",
      "5. par le licou de la lettre de calyste , elle fut traversée par la pointe d'une idée cruelle . \n",
      "\n",
      "6. \n",
      "\n",
      "7. \n",
      "\n",
      "8. \n",
      "\n",
      "9. les déchirera . \n",
      "\n",
      "10. qui vers midi fut constaté . \n",
      "\n",
      "11. soucient plus guère . \n",
      "\n",
      "12. \n",
      "\n",
      "13. \n",
      "\n",
      "14. coudes sur le dossier du fauteuil occupé par le vieux gentilhomme en imitant , sans le savoir , surpassait en éclat le lever sidéral des \n",
      "\n",
      "15. \n",
      "\n",
      "16. \n",
      "\n",
      "17. cette nomination froissa beaucoup le juge desfondrilles , toujours archéologue et plus que jamais suppléant . \n",
      "\n",
      "18. \n",
      "\n",
      "19. extravagantes dont les bougies jaunes ne s'allumaient qu'aux jours où la présidente dépouillait de son enveloppe verte un vieux lustre à pendeloques de cristal de \n",
      "\n",
      "20. entouré d'une margelle , et à poulie maintenue dans une branche de fer courbée , qu'embrassait une vigne aux pampres flétris , rougis , brouis \n",
      "\n",
      "21. \n",
      "\n",
      "22. est-ce moi enfin , moi qui viens de relire ta dernière lettre , je t'aurai peint cet infernal paradis de paris en te disant \n",
      "\n",
      "23. fût-ce une désolation dans tout le sancerrois . \n",
      "\n",
      "24. vieux politiques , avaient trouvé moyen d'éluder la charte . \n",
      "\n",
      "25. d'exploitation pour ses immenses domaines de sardaigne , dont les ressources sont bien connues à marseille . \n",
      "\n",
      "26. \n",
      "\n",
      "27. bien . \n",
      "\n",
      "28. \n",
      "\n",
      "29. \n",
      "\n",
      "30. mais aussi depuis trente ans ne s ' y dénature pas , elle épouse dieu . \n",
      "\n",
      "31. . \n",
      "\n",
      "32. nécessité de congédier lousteau qui feignait de ne pas avoir à en dire davantage était étouffé sous la douleur du moment . \n",
      "\n",
      "33. à cette main molle en apparence et que rien ne saurait exprimer . \n",
      "\n",
      "34. n'êtes pas assez mal ici pour vous en aller , lui dit vignon . \n",
      "\n",
      "35. mon gros père , vous y gagnerez ! » en effet , aurélie s'arrangea pour déployer de nouvelles vertus dans cette nouvelle phase . \n",
      "\n",
      "36. . \n",
      "\n",
      "37. la littérature heureuse , c'est la brillante courtisane insolente , qui a des écus . \n",
      "\n",
      "38. \n",
      "\n",
      "39. il ajourna sa réponse au moment où il était en joie , il est peut-être nécessaire de traduire métaphysiquement les impressions extraordinaires \n",
      "\n",
      "40. eh ! \n",
      "\n",
      "41. ! ... \n",
      "\n",
      "42. \n",
      "\n",
      "43. qui avait des bottes et des éperons , poussa l'autre par un coup de coude de mademoiselle d'hérouville , m ' a fait des propositions \n",
      "\n",
      "44. ’ immenses espaces. -- la mort dût-elle m ’ attendre au sortir de la classe de coulon . \n",
      "\n",
      "45. faisant un geste d ’ effroi . \n",
      "\n",
      "46. « le mariage de monsieur le président cruchot n'était pas aussi avancé qu'on le croyait. -- quoique monsieur de froidfond ait \n",
      "\n",
      "47. ce qu'elle eût été sans son séjour en province , grande dame . \n",
      "\n",
      "48. . \n",
      "\n",
      "49. j'ai douté de la vie et des sentiments d'albert . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_generated_sentence(25, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un second modèle de langage de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant par exemple le modèle de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tester aussi sur le corpus de test et comparer les scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloze test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer un mot sur 7 dans le corpus de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode lm.generate avec du contexte, demander au modèle de langage de prédire ces mots (en utilisant donc 2-4 mots précédents). Quelle est la performance du système ? Comparer les modèles générés en (2) et en (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générez un texte avec les mots en question (1 mot sur 7) remplacés par des blancs, et passez-le à un autre binôme : quelle est leur performance pour deviner les mots ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merci d’envoyer votre notebook Jupyter par email au professeur avant le vendredi 14 juin à 23h59."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
