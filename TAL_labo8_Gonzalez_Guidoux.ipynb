{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labo 8 : modèles de langage / Cloze Test\n",
    "Par Guidoux Vincent et Gonzalez Montes Nathan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectif et plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de ce labo est d'entraîner des modèles de langues (EN : language models) sous NLTK en utilisant le package nltk.lm. Les modèles seront entraînés sur des romans de Balzac en français\n",
    "(fournis par le projet Gutenberg), et leurs performances seront mesurées par leur perplexité sur de nouveaux textes. Les modèles serviront également à deviner des mots cachés dans un texte, et ici leurs performances seront comparées à celles des humains sur cette même tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Vincent\n",
      "[nltk_data]     Guidoux\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import nltk.lm\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "import os, codecs\n",
    "from urllib import request\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenir les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Télécharger les dix romans de la Comédie humaine de Balzac en français, enlever les notices en anglais au début et à la fin, puis les assembler en un corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dl_gutenberg_raw(url):\n",
    "    print(\"dowloading \\\"{}\\\" ... \".format(url))\n",
    "    \n",
    "    response = request.urlopen(url)\n",
    "    raw = response.read().decode('utf8')\n",
    "    \n",
    "    # enlever les notices en anglais au début \n",
    "    begin = raw.find(\"Libraries)\") + 10\n",
    "    # et à la fin\n",
    "    end = raw.find(\"*** END OF THIS PROJECT\")\n",
    "    \n",
    "    return raw[begin:end].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_1 = \"https://www.gutenberg.org/ebooks/41211.txt.utf-8\"\n",
    "volume_2 = \"https://www.gutenberg.org/files/43851/43851-0.txt\"\n",
    "volume_3 = \"https://www.gutenberg.org/files/45060/45060-0.txt\"\n",
    "volume_4 = \"https://www.gutenberg.org/files/48082/48082-0.txt\"\n",
    "volume_5 = \"https://www.gutenberg.org/files/49482/49482-0.txt\"\n",
    "volume_6 = \"https://www.gutenberg.org/files/51381/51381-0.txt\"\n",
    "volume_7 = \"https://www.gutenberg.org/files/52831/52831-0.txt\"\n",
    "volume_8 = \"https://www.gutenberg.org/files/54723/54723-0.txt\"\n",
    "volume_9 = \"https://www.gutenberg.org/files/55860/55860-0.txt\"\n",
    "volume_10 = \"https://www.gutenberg.org/files/58244/58244-0.txt\"\n",
    "\n",
    "balzac = [volume_1, \n",
    "          volume_2, \n",
    "          volume_3, \n",
    "          volume_4, \n",
    "          volume_5, \n",
    "          volume_6, \n",
    "          volume_7, \n",
    "          volume_8,\n",
    "          volume_9, \n",
    "          volume_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser une procédure à laquelle on donnera la liste de noms de fichiers ou des URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dowloading \"https://www.gutenberg.org/ebooks/41211.txt.utf-8\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/43851/43851-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/45060/45060-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/48082/48082-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/49482/49482-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/51381/51381-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/52831/52831-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/54723/54723-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/55860/55860-0.txt\" ... \n",
      "dowloading \"https://www.gutenberg.org/files/58244/58244-0.txt\" ... \n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\n",
    "\n",
    "for volume_url in balzac:\n",
    "    corpus += dl_gutenberg_raw(volume_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 12214531 caractères dans ce corpus.\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} caractères dans ce corpus.\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder le texte résultant : quelle taille fait-il en Ko ou Mo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"la_comedie_humaine.txt\"\n",
    "\n",
    "if os.path.exists(filename1): \n",
    "    os.remove(filename1)\n",
    "fd = codecs.open(filename1, 'a', 'utf8')\n",
    "\n",
    "try:\n",
    "    fd.write(corpus)\n",
    "    \n",
    "\n",
    "finally:  \n",
    "    fd.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il fait **12'258 [ko]** et **12 [Mo]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenter et tokenizer en une liste de listes de mots, y compris les ponctuations (une liste = une phrase)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_nettoye = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_nettoye = corpus_nettoye.replace('.\\r\\n',' ') # on nettoie les retours à la ligne\n",
    "# corpus_nettoye = corpus_nettoye.replace('\\r\\n.',' ') # on nettoie les retours à la ligne\n",
    "# corpus_nettoye = corpus_nettoye.replace('\\r\\n',' ') # on nettoie les retours à la ligne\n",
    "corpus_nettoye = corpus_nettoye.replace('_',' ') # on nettoie les _\n",
    "corpus_nettoye = corpus_nettoye.replace('--',' ') # on nettoie les _--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = nltk.sent_tokenize(corpus_nettoye, language=\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 102617 phrases dans le corpus\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} phrases dans le corpus\".format(len(tokenized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [nltk.word_tokenize(sentence) for sentence in tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_nb = 0\n",
    "for sentence in tokenized:\n",
    "    word_nb += len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2320674 mots dans ce corpus\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} mots dans ce corpus\".format(word_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized[87:93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized[1506:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized[7000:7005]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire un fragment (environ 2000 mots) qui servira de donnée de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_test(sentences):\n",
    "    \n",
    "    train_percentage = 0.03\n",
    "\n",
    "    random.shuffle(sentences)\n",
    "    \n",
    "    sentences_length = len(sentences)\n",
    "    \n",
    "    train_set_length = int(len(sentences) * train_percentage)\n",
    "    \n",
    "    test_set = sentences[ :train_set_length]\n",
    "    \n",
    "    train_set = sentences[train_set_length: ]\n",
    "\n",
    "    return (train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = separate_train_test(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 99539 phrases dans le train_set et 3078 dans le test_set\n"
     ]
    }
   ],
   "source": [
    "print(\"Il y a {} phrases dans le train_set et {} dans le test_set\".format(\n",
    "        len(train_set),\n",
    "        len(test_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un premier modèle de langage de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant les instructions disponibles pour le module NLTK LM, entraîner un modèle de langage sur les données d'entraînement. Attention, le package lm n'est disponible qu'à partir de NLTK version 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commencer avec un modèle MLE à l'ordre 2, comme montré dans le tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, vocab = padded_everygram_pipeline(order, tokenized)\n",
    "train, vocab = padded_everygram_pipeline(order, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = MLE(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cela a pris 102.521 secondes pour entraîner le modèle d'ordre 5\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "lm.fit(train, vocab)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Cela a pris {:.3f} secondes pour entraîner le modèle d'ordre {}\".format(\n",
    "            (end-begin), order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculer la perplexité du modèle sur l’ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générer quelques phrases dans le style de Balzac selon les explications de NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_sentence(length, sentence_nb):\n",
    "\n",
    "    for i in range(sentence_nb):\n",
    "        sentence = \"{}. \".format(i)\n",
    "        for word in lm.generate(length):\n",
    "            if word != \"<s>\" and word != \"</s>\":\n",
    "                sentence += word + \" \"\n",
    "        print(sentence + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_generated_sentence(8, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_generated_sentence(25, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraîner un second modèle de langage de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant par exemple le modèle de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le tester aussi sur le corpus de test et comparer les scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloze test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supprimer un mot sur 7 dans le corpus de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trésor', 'immense']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.generate(text_seed=['David', 'Jaquet','est', 'un'], num_words=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loose_word = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_longer_than(variable):\n",
    "    if len(variable) >= loose_word: \n",
    "        return True\n",
    "    else: \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 2577 phrases de 7+ mots dans le train set\n"
     ]
    }
   ],
   "source": [
    "filtered = filter(is_longer_than, test_set)\n",
    "\n",
    "filtered = list(filtered)\n",
    "\n",
    "print(\"Il y a {} phrases de 7+ mots dans le train set\".format(len(filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_sentence(list_of_words):\n",
    "    sentence = \"\"\n",
    "    for word in list_of_words:\n",
    "        sentence += word + \" \"\n",
    "    return sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant la méthode lm.generate avec du contexte, demander au modèle de langage de prédire ces mots (en utilisant donc 2-4 mots précédents). Quelle est la performance du système ? Comparer les modèles générés en (2) et en (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "#for word_nb in range(2,3):\n",
    "gessed_words = set()\n",
    "\n",
    "for i,sentence in enumerate(filtered[:40000]):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "#         print(\"current sentence :\", list_to_sentence(sentence))\n",
    "#         print(\"mots à tester : \", list_to_sentence(sentence[2:6]))\n",
    "    gessed_word = lm.generate(text_seed=lm.generate(text_seed=sentence[4:6], num_words=1))\n",
    "    # print(\"mot découvert : \", gessed_word)\n",
    "    if gessed_word == sentence[6]:\n",
    "#             print(\"current sentence :\", list_to_sentence(sentence))\n",
    "#             print(\"gessed sentence : {}{} {}\".format(list_to_sentence(sentence[:6]),gessed_word,list_to_sentence(sentence[7:])) )\n",
    "#             print(\"\\n\")\n",
    "        gessed_words.add(gessed_word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',', '.', 'et', 'une'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gessed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'!', ',', '.', 'belle', 'et', 'la', 'que', 'sa', '|'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Générez un texte avec les mots en question (1 mot sur 7) remplacés par des blancs, et passez-le à un autre binôme : quelle est leur performance pour deviner les mots ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for word_nb in range(2,5):\n",
    "    print(word_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merci d’envoyer votre notebook Jupyter par email au professeur avant le vendredi 14 juin à 23h59."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
